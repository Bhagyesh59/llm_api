{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "blwv_5zLuKGX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: pymongo[srv]\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
            "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: requests in ./env/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Downloading torch-2.4.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Downloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: Pillow in ./env/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jinja2 in ./env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
            "Downloading regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
            "Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
            "Downloading tokenizers-0.20.0-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.1-cp311-none-macosx_11_0_arm64.whl (62.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, regex, PyPDF2, networkx, joblib, fsspec, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed PyPDF2-3.0.1 filelock-3.16.1 fsspec-2024.9.0 huggingface-hub-0.25.1 joblib-1.4.2 mpmath-1.3.0 networkx-3.3 regex-2024.9.11 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.1.1 sympy-1.13.3 threadpoolctl-3.5.0 tokenizers-0.20.0 torch-2.4.1 transformers-4.45.1\n",
            "Requirement already satisfied: numpy in ./env/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in ./env/lib/python3.11/site-packages (1.14.1)\n",
            "Requirement already satisfied: openai in ./env/lib/python3.11/site-packages (1.49.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./env/lib/python3.11/site-packages (from openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./env/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./env/lib/python3.11/site-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./env/lib/python3.11/site-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./env/lib/python3.11/site-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./env/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain in ./env/lib/python3.11/site-packages (0.3.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain) (3.10.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in ./env/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./env/lib/python3.11/site-packages (from langchain) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./env/lib/python3.11/site-packages (from langchain-openai) (1.49.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./env/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.4/982.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.2.1 tiktoken-0.8.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain_community) (3.10.7)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in ./env/lib/python3.11/site-packages (from langchain_community) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in ./env/lib/python3.11/site-packages (from langchain_community) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./env/lib/python3.11/site-packages (from langchain_community) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in ./env/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain-experimental) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in ./env/lib/python3.11/site-packages (from langchain-experimental) (0.3.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.7)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.13.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in ./env/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2024.8.30)\n",
            "Requirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.5)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./env/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
            "Downloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
            "Installing collected packages: langchain-experimental\n",
            "Successfully installed langchain-experimental-0.3.2\n",
            "Requirement already satisfied: langchain in ./env/lib/python3.11/site-packages (0.3.1)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.10.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain) (3.10.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in ./env/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./env/lib/python3.11/site-packages (from langchain) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
            "Downloading pymongo-4.10.1-cp311-cp311-macosx_11_0_arm64.whl (889 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m889.5/889.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "Installing collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.10.1\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in ./env/lib/python3.11/site-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in ./env/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
            "  Downloading cryptography-43.0.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
            "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
            "  Downloading cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
            "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-43.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl (178 kB)\n",
            "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
            "Successfully installed cffi-1.17.1 cryptography-43.0.1 pdfminer.six-20231228 pdfplumber-0.11.4 pycparser-2.22 pypdfium2-4.30.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.1\n",
            "Collecting langchain-mongodb\n",
            "  Downloading langchain_mongodb-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in ./env/lib/python3.11/site-packages (from langchain-mongodb) (0.3.6)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain-mongodb) (1.26.4)\n",
            "Requirement already satisfied: pymongo<5.0,>=4.6.1 in ./env/lib/python3.11/site-packages (from langchain-mongodb) (4.10.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-mongodb) (4.12.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in ./env/lib/python3.11/site-packages (from pymongo<5.0,>=4.6.1->langchain-mongodb) (2.6.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-mongodb) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-mongodb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-mongodb) (2.23.4)\n",
            "Requirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (4.6.0)\n",
            "Requirement already satisfied: certifi in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (1.0.5)\n",
            "Requirement already satisfied: idna in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (3.10)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-mongodb) (2.2.3)\n",
            "Downloading langchain_mongodb-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-mongodb\n",
            "Successfully installed langchain-mongodb-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo[srv] sentence-transformers\n",
        "!pip install PyPDF2 transformers sentence-transformers\n",
        "!pip install numpy scipy\n",
        "!pip install openai\n",
        "!pip install  langchain langchain-openai\n",
        "!pip install langchain_community\n",
        "!pip install langchain-experimental\n",
        "!pip install langchain pymongo\n",
        "!pip install pdfplumber\n",
        "!pip install pypdf\n",
        "!pip install langchain-mongodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "kOvN2f5FuRd3",
        "outputId": "ee745b46-9eff-4abd-debd-d71e024b8c9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wX88U4wFuVvK"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"Data Scientist Job Description.pdf\")\n",
        "pages = loader.load()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Research & Innovation: Stay current with data science trends, experimenting with new tools\\nand techniques to improve our data capabilities.\\nMentorship: Guide junior team members and foster a culture of learning through workshops\\nand internal knowledge sharing.\\nRequired Qualiﬁcations\\nEducation: Bachelor’s or Master’s in Data Science, Statistics, Computer Science, Mathematics, or\\na related ﬁeld (PhD is a plus).\\nSkills:\\nProﬁciency in Python or R, with strong knowledge of data libraries like Pandas, Numpy, and\\nScikit-learn.\\nExperience with machine learning frameworks (TensorFlow, PyTorch) and big data tools\\n(Hadoop, Spark).\\nStrong SQL skills and familiarity with NoSQL databases like MongoDB.\\nKnowledge of cloud platforms (AWS, Google Cloud, or Azure).\\nExperience: 3+ years working with large datasets, building machine learning models, and\\ndelivering impactful data solutions.\\nPreferred Qualiﬁcations\\nExperience with time-series data, NLP techniques, and A/B testing.\\nFamiliarity with deep learning and MLOps for scaling models.\\nPersonal Attributes\\nCuriosity & Innovation: A passion for data and ﬁnding creative solutions to complex problems.\\nAdaptability: Ability to thrive in a dynamic, fast-paced environment.\\nTeam Player: Collaborative mindset with a willingness to share knowledge and work cross-\\nfunctionally.\\nSelf-Driven: Strong work ethic and ownership of projects from start to ﬁnish.\\nWhy Join Us?\\nAt Krowstel, we oﬀer:\\nCompetitive salary and beneﬁts.\\nFlexible working arrangements, including remote options.\\nA collaborative, growth-oriented culture with opportunities for career advancement.\\nAccess to cutting-edge projects that push the boundaries of data science.\\nHow to Apply\\nExcited about joining our team? Submit your resume, cover letter, and a portfolio (if available) to\\nkrowstel@gmail.com. In your cover letter, tell us about your experience and how you’d contribute to\\nour data-driven future.\\nThis version retains all key details while presenting a more succinct and approachable format. Let me\\nknow what you think or if you need any further tweaks!\\nChatGPT can make mistakes. Check important info.\\nPrinted using Save ChatGPT as PDF, powered by PDFCrowd HTML to PDF API. 2/2'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gNLxYkstucA8"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "def get_embedding_data(data,chunk_size,chunk_overlap):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = chunk_size,\n",
        "    chunk_overlap  = chunk_overlap,\n",
        "    length_function = len,\n",
        "  )\n",
        "  return text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T9JjeCgsu5VE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks created: 31\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Data Scientist Job Description\\nThis job description is comprehensive and very well structured! It clearly outlines the responsibilities,'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='required qualiﬁcations, and company values. It eﬀectively conveys the role and the opportunities for\\ngrowth at Krowstel. The only thing that might be worth considering is to condense some sections'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content=\"slightly, especially if you're sharing this on platforms with word limits or where readers may skim.\\nOtherwise, it looks great as is!\"),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content=\"Otherwise, it looks great as is!\\nLet me know if you'd like help with any further edits or adjustm ents.\\nHere’s a more concise and engaging rewrite of the job description:\\nJob Title: Data Scientist\"),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Job Title: Data Scientist\\nCompany Overview\\nAt Krowstel, we are passionate about leveraging data to create innovative solutions that drive'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='business value. We’re a forward-thinking company that fosters collaboration, continuous learning, and'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content=\"excellence. Our team tackles complex challenges, delivering actionable insights to shape our data-\\ndriven future. We're looking for a skilled and motivated Data Scientist to join our growing team.\"),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Job Overview\\nAs a Data Scientist at Krowstel, you’ll analyze complex datasets, develop predictive models, and'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='implement machine learning algorithms to drive critical business decisions. You will collaborate with'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='data engineers, developers, analysts, and product teams to deliver impactful data solutions. If you’re\\npassionate about working with data, have a strong programming background, and are excited to'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='explore new technologies, we’d love to have you on board.\\nKey Responsibilities\\nData Collection & Preprocessing: Collaborate with data engineers to collect, clean, and'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='preprocess data from various sources. Ensur e data quality and automate data pipelines.\\nExploratory Data Analysis: Uncover trends, relationships, and actionable insights through in-'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='depth data analysis and visualization.\\nModel Development: Build and validate machine learning models for tasks like customer\\nsegmentation, demand forecasting, and fraud detection.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Model Optimization: Regularly evaluate model performance and ﬁne-tune algorithms to\\nenhance accuracy and eﬃciency.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='enhance accuracy and eﬃciency.\\nData Visualization & Reporting: Create dashboards and reports for stakeholders using tools\\nlike Tableau or Python-based custom visualizations.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Collaboration: Work with engineers to deploy models and product teams to translate business\\nneeds into data solutions.\\nPrinted using Save ChatGPT as PDF, powered by PDFCrowd HTML to PDF API. 1/2'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Research & Innovation: Stay current with data science trends, experimenting with new tools\\nand techniques to improve our data capabilities.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='and techniques to improve our data capabilities.\\nMentorship: Guide junior team members and foster a culture of learning through workshops\\nand internal knowledge sharing.\\nRequired Qualiﬁcations'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Required Qualiﬁcations\\nEducation: Bachelor’s or Master’s in Data Science, Statistics, Computer Science, Mathematics, or\\na related ﬁeld (PhD is a plus).\\nSkills:'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='a related ﬁeld (PhD is a plus).\\nSkills:\\nProﬁciency in Python or R, with strong knowledge of data libraries like Pandas, Numpy, and\\nScikit-learn.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Scikit-learn.\\nExperience with machine learning frameworks (TensorFlow, PyTorch) and big data tools\\n(Hadoop, Spark).\\nStrong SQL skills and familiarity with NoSQL databases like MongoDB.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Knowledge of cloud platforms (AWS, Google Cloud, or Azure).\\nExperience: 3+ years working with large datasets, building machine learning models, and\\ndelivering impactful data solutions.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='delivering impactful data solutions.\\nPreferred Qualiﬁcations\\nExperience with time-series data, NLP techniques, and A/B testing.\\nFamiliarity with deep learning and MLOps for scaling models.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Personal Attributes\\nCuriosity & Innovation: A passion for data and ﬁnding creative solutions to complex problems.\\nAdaptability: Ability to thrive in a dynamic, fast-paced environment.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Team Player: Collaborative mindset with a willingness to share knowledge and work cross-\\nfunctionally.\\nSelf-Driven: Strong work ethic and ownership of projects from start to ﬁnish.\\nWhy Join Us?'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='Why Join Us?\\nAt Krowstel, we oﬀer:\\nCompetitive salary and beneﬁts.\\nFlexible working arrangements, including remote options.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='A collaborative, growth-oriented culture with opportunities for career advancement.\\nAccess to cutting-edge projects that push the boundaries of data science.\\nHow to Apply'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='How to Apply\\nExcited about joining our team? Submit your resume, cover letter, and a portfolio (if available) to'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='krowstel@gmail.com. In your cover letter, tell us about your experience and how you’d contribute to\\nour data-driven future.'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='our data-driven future.\\nThis version retains all key details while presenting a more succinct and approachable format. Let me\\nknow what you think or if you need any further tweaks!'),\n",
              " Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 1}, page_content='ChatGPT can make mistakes. Check important info.\\nPrinted using Save ChatGPT as PDF, powered by PDFCrowd HTML to PDF API. 2/2')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs = get_embedding_data(pages, 200, 50)\n",
        "print(f\"Total chunks created: {len(docs)}\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VMnhSx_dxrJT",
        "outputId": "bf303102-308f-4d09-fe4a-403f01aaf2e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'Data Scientist Job Description.pdf', 'page': 0}, page_content='Data Scientist Job Description\\nThis job description is comprehensive and very well structured! It clearly outlines the responsibilities,')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlreW_36xkvz",
        "outputId": "5dd1e9bf-28e0-4d15-da79-1d7d88ab5dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Scientist Job Description\n",
            "This job description is comprehensive and very well structured! It clearly outlines the responsibilities,\n",
            "required qualiﬁcations, and company values. It eﬀectively conveys the role and the opportunities for\n",
            "growth at Krowstel. The only thing that might be worth considering is to condense some sections\n",
            "slightly, especially if you're sharing this on platforms with word limits or where readers may skim.\n",
            "Otherwise, it looks great as is!\n",
            "Otherwise, it looks great as is!\n",
            "Let me know if you'd like help with any further edits or adjustm ents.\n",
            "Here’s a more concise and engaging rewrite of the job description:\n",
            "Job Title: Data Scientist\n",
            "Job Title: Data Scientist\n",
            "Company Overview\n",
            "At Krowstel, we are passionate about leveraging data to create innovative solutions that drive\n",
            "business value. We’re a forward-thinking company that fosters collaboration, continuous learning, and\n",
            "excellence. Our team tackles complex challenges, delivering actionable insights to shape our data-\n",
            "driven future. We're looking for a skilled and motivated Data Scientist to join our growing team.\n",
            "Job Overview\n",
            "As a Data Scientist at Krowstel, you’ll analyze complex datasets, develop predictive models, and\n",
            "implement machine learning algorithms to drive critical business decisions. You will collaborate with\n",
            "data engineers, developers, analysts, and product teams to deliver impactful data solutions. If you’re\n",
            "passionate about working with data, have a strong programming background, and are excited to\n",
            "explore new technologies, we’d love to have you on board.\n",
            "Key Responsibilities\n",
            "Data Collection & Preprocessing: Collaborate with data engineers to collect, clean, and\n",
            "preprocess data from various sources. Ensur e data quality and automate data pipelines.\n",
            "Exploratory Data Analysis: Uncover trends, relationships, and actionable insights through in-\n",
            "depth data analysis and visualization.\n",
            "Model Development: Build and validate machine learning models for tasks like customer\n",
            "segmentation, demand forecasting, and fraud detection.\n",
            "Model Optimization: Regularly evaluate model performance and ﬁne-tune algorithms to\n",
            "enhance accuracy and eﬃciency.\n",
            "enhance accuracy and eﬃciency.\n",
            "Data Visualization & Reporting: Create dashboards and reports for stakeholders using tools\n",
            "like Tableau or Python-based custom visualizations.\n",
            "Collaboration: Work with engineers to deploy models and product teams to translate business\n",
            "needs into data solutions.\n",
            "Printed using Save ChatGPT as PDF, powered by PDFCrowd HTML to PDF API. 1/2\n",
            "Research & Innovation: Stay current with data science trends, experimenting with new tools\n",
            "and techniques to improve our data capabilities.\n",
            "and techniques to improve our data capabilities.\n",
            "Mentorship: Guide junior team members and foster a culture of learning through workshops\n",
            "and internal knowledge sharing.\n",
            "Required Qualiﬁcations\n",
            "Required Qualiﬁcations\n",
            "Education: Bachelor’s or Master’s in Data Science, Statistics, Computer Science, Mathematics, or\n",
            "a related ﬁeld (PhD is a plus).\n",
            "Skills:\n",
            "a related ﬁeld (PhD is a plus).\n",
            "Skills:\n",
            "Proﬁciency in Python or R, with strong knowledge of data libraries like Pandas, Numpy, and\n",
            "Scikit-learn.\n",
            "Scikit-learn.\n",
            "Experience with machine learning frameworks (TensorFlow, PyTorch) and big data tools\n",
            "(Hadoop, Spark).\n",
            "Strong SQL skills and familiarity with NoSQL databases like MongoDB.\n",
            "Knowledge of cloud platforms (AWS, Google Cloud, or Azure).\n",
            "Experience: 3+ years working with large datasets, building machine learning models, and\n",
            "delivering impactful data solutions.\n",
            "delivering impactful data solutions.\n",
            "Preferred Qualiﬁcations\n",
            "Experience with time-series data, NLP techniques, and A/B testing.\n",
            "Familiarity with deep learning and MLOps for scaling models.\n",
            "Personal Attributes\n",
            "Curiosity & Innovation: A passion for data and ﬁnding creative solutions to complex problems.\n",
            "Adaptability: Ability to thrive in a dynamic, fast-paced environment.\n",
            "Team Player: Collaborative mindset with a willingness to share knowledge and work cross-\n",
            "functionally.\n",
            "Self-Driven: Strong work ethic and ownership of projects from start to ﬁnish.\n",
            "Why Join Us?\n",
            "Why Join Us?\n",
            "At Krowstel, we oﬀer:\n",
            "Competitive salary and beneﬁts.\n",
            "Flexible working arrangements, including remote options.\n",
            "A collaborative, growth-oriented culture with opportunities for career advancement.\n",
            "Access to cutting-edge projects that push the boundaries of data science.\n",
            "How to Apply\n",
            "How to Apply\n",
            "Excited about joining our team? Submit your resume, cover letter, and a portfolio (if available) to\n",
            "krowstel@gmail.com. In your cover letter, tell us about your experience and how you’d contribute to\n",
            "our data-driven future.\n",
            "our data-driven future.\n",
            "This version retains all key details while presenting a more succinct and approachable format. Let me\n",
            "know what you think or if you need any further tweaks!\n",
            "ChatGPT can make mistakes. Check important info.\n",
            "Printed using Save ChatGPT as PDF, powered by PDFCrowd HTML to PDF API. 2/2\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "  print(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S-9varTySnv",
        "outputId": "fb004989-4b60-43e9-8e9b-32b4e937b28d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bhagyeshshinde/Documents/new_test_project/env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/Users/bhagyeshshinde/Documents/new_test_project/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s0T12Kg5BX2P"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "import json\n",
        "from typing import List, Union\n",
        "import hashlib\n",
        "\n",
        "def deterministic_uuid(content: Union[str, bytes]) -> str:\n",
        "    \"\"\"Creates deterministic UUID on hash value of string or byte content.\n",
        "\n",
        "    Args:\n",
        "        content: String or byte representation of data.\n",
        "\n",
        "    Returns:\n",
        "        UUID of the content.\n",
        "    \"\"\"\n",
        "    if isinstance(content, str):\n",
        "        content_bytes = content.encode(\"utf-8\")\n",
        "    elif isinstance(content, bytes):\n",
        "        content_bytes = content\n",
        "    else:\n",
        "        raise ValueError(f\"Content type {type(content)} not supported!\")\n",
        "\n",
        "    hash_object = hashlib.sha256(content_bytes)\n",
        "    hash_hex = hash_object.hexdigest()\n",
        "    namespace = uuid.UUID(\"00000000-0000-0000-0000-000000000000\")\n",
        "    content_uuid = str(uuid.uuid5(namespace, hash_hex))\n",
        "\n",
        "    return content_uuid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "52PUGYGtvgZH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def doc_embedor(docs: List, jd_name: str):\n",
        "    embedded_docs = []\n",
        "    for doc in docs:\n",
        "        # Assuming `model.encode` generates embeddings for the document\n",
        "        embedding = model.encode(doc.page_content)  \n",
        "        embedding = embedding.tolist()\n",
        "\n",
        "        # Create a deterministic UUID for the document content\n",
        "        id = deterministic_uuid(doc.page_content)+\"-\"+ jd_name\n",
        "\n",
        "        # Append the document data and embedding to the embedded_docs list\n",
        "        embedded_docs.append({\"jd_id\": id,\"data\": doc.page_content, \"embedding\": embedding})\n",
        "\n",
        "    return embedded_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kSwotJlWyaCJ"
      },
      "outputs": [],
      "source": [
        "jd_name=\"data_science\"\n",
        "ready_data=doc_embedor(docs,jd_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'jd_id': '5a5c3d24-210d-54c3-a401-1c9d188e0783-data_science',\n",
              " 'data': 'Data Scientist Job Description\\nThis job description is comprehensive and very well structured! It clearly outlines the responsibilities,',\n",
              " 'embedding': [-0.05457000806927681,\n",
              "  0.02108445018529892,\n",
              "  0.030929798260331154,\n",
              "  0.01903536543250084,\n",
              "  -0.008240333758294582,\n",
              "  -0.1207597553730011,\n",
              "  0.00806516595184803,\n",
              "  -0.04472535103559494,\n",
              "  -0.1341743916273117,\n",
              "  0.004138631746172905,\n",
              "  -0.03924109786748886,\n",
              "  -0.0925382673740387,\n",
              "  0.03216812014579773,\n",
              "  -0.009953287430107594,\n",
              "  -0.11048724502325058,\n",
              "  0.035718828439712524,\n",
              "  -0.035564813762903214,\n",
              "  -0.06998210400342941,\n",
              "  -0.0055823246948421,\n",
              "  -0.06351323425769806,\n",
              "  -0.007126770447939634,\n",
              "  0.01045672595500946,\n",
              "  0.022484177723526955,\n",
              "  0.014996173791587353,\n",
              "  -0.019574664533138275,\n",
              "  0.09571055322885513,\n",
              "  0.03964027017354965,\n",
              "  0.006621555890887976,\n",
              "  0.013690123334527016,\n",
              "  -0.0021875121165066957,\n",
              "  -0.015700802206993103,\n",
              "  -0.00012661333312280476,\n",
              "  0.06323864310979843,\n",
              "  0.1297650784254074,\n",
              "  -0.016043439507484436,\n",
              "  0.0691341832280159,\n",
              "  -0.046687670052051544,\n",
              "  -0.024470500648021698,\n",
              "  -0.013090794906020164,\n",
              "  0.019793851301074028,\n",
              "  0.014097430743277073,\n",
              "  -0.053340498358011246,\n",
              "  -0.028763271868228912,\n",
              "  -0.00639037461951375,\n",
              "  -0.011697999201714993,\n",
              "  -0.03692927211523056,\n",
              "  0.033684141933918,\n",
              "  -0.11035828292369843,\n",
              "  -0.05230732634663582,\n",
              "  0.03611547127366066,\n",
              "  -0.07255695760250092,\n",
              "  -0.04269837960600853,\n",
              "  0.010854363441467285,\n",
              "  -0.005301796365529299,\n",
              "  -0.019212208688259125,\n",
              "  0.03746993839740753,\n",
              "  0.039725180715322495,\n",
              "  -0.035581544041633606,\n",
              "  -0.04361764341592789,\n",
              "  -0.044249020516872406,\n",
              "  0.011178997345268726,\n",
              "  -0.022918662056326866,\n",
              "  -0.06621886044740677,\n",
              "  0.08505977690219879,\n",
              "  0.13392280042171478,\n",
              "  -0.030090486630797386,\n",
              "  -0.03756188228726387,\n",
              "  0.015486304648220539,\n",
              "  -0.008739765733480453,\n",
              "  -0.08967604488134384,\n",
              "  -0.05597963184118271,\n",
              "  0.003727987874299288,\n",
              "  -0.037897467613220215,\n",
              "  0.0419868528842926,\n",
              "  0.03188440203666687,\n",
              "  -0.0001419631444150582,\n",
              "  0.006715514697134495,\n",
              "  0.008962432853877544,\n",
              "  0.11263107508420944,\n",
              "  -0.012030435726046562,\n",
              "  0.02169312722980976,\n",
              "  0.003634208580479026,\n",
              "  -0.019908970221877098,\n",
              "  0.04666963219642639,\n",
              "  -0.03544020652770996,\n",
              "  -0.09598448872566223,\n",
              "  -0.03477977216243744,\n",
              "  -0.024233510717749596,\n",
              "  -0.01033959910273552,\n",
              "  -0.01966000162065029,\n",
              "  0.06037333980202675,\n",
              "  -0.05454782396554947,\n",
              "  0.06375778466463089,\n",
              "  0.005373192951083183,\n",
              "  -0.09198564291000366,\n",
              "  0.05399278923869133,\n",
              "  -0.011295018717646599,\n",
              "  -0.02650945447385311,\n",
              "  0.024749796837568283,\n",
              "  -0.06737875193357468,\n",
              "  -0.011094167828559875,\n",
              "  0.011856341734528542,\n",
              "  0.019829435274004936,\n",
              "  0.04107087850570679,\n",
              "  -0.11103925853967667,\n",
              "  -0.060728952288627625,\n",
              "  -0.009740492329001427,\n",
              "  0.0002807837154250592,\n",
              "  -0.057129111140966415,\n",
              "  -0.0070935385301709175,\n",
              "  -0.03039679303765297,\n",
              "  0.06723208725452423,\n",
              "  -0.034628842025995255,\n",
              "  0.017956992611289024,\n",
              "  0.025631550699472427,\n",
              "  0.040717657655477524,\n",
              "  -0.16969642043113708,\n",
              "  0.07718151062726974,\n",
              "  -0.001949158962816,\n",
              "  0.04186338558793068,\n",
              "  -0.0125855328515172,\n",
              "  0.054081276059150696,\n",
              "  -0.03299151360988617,\n",
              "  -0.026831071823835373,\n",
              "  -0.0002496645029168576,\n",
              "  -0.05843634158372879,\n",
              "  -0.002023956272751093,\n",
              "  -3.471598119201016e-33,\n",
              "  -0.028691239655017853,\n",
              "  0.03978424891829491,\n",
              "  0.04250697046518326,\n",
              "  0.06650789082050323,\n",
              "  0.022544005885720253,\n",
              "  -0.005922586657106876,\n",
              "  -0.06999172270298004,\n",
              "  0.0341128371655941,\n",
              "  -0.02589450776576996,\n",
              "  0.11519797891378403,\n",
              "  -0.05641291290521622,\n",
              "  0.016310609877109528,\n",
              "  -0.006644252687692642,\n",
              "  0.09612535685300827,\n",
              "  -0.07571876794099808,\n",
              "  0.03638235479593277,\n",
              "  -0.0504508838057518,\n",
              "  0.13837218284606934,\n",
              "  -0.03728196769952774,\n",
              "  0.06629745662212372,\n",
              "  0.052589233964681625,\n",
              "  0.03536590561270714,\n",
              "  -0.012377039529383183,\n",
              "  0.01942301355302334,\n",
              "  0.09383515268564224,\n",
              "  -0.013483162969350815,\n",
              "  0.004352697636932135,\n",
              "  -0.02394046075642109,\n",
              "  0.043317534029483795,\n",
              "  0.026896586641669273,\n",
              "  0.01746509224176407,\n",
              "  -0.05522851273417473,\n",
              "  -0.03202478960156441,\n",
              "  -0.004770840052515268,\n",
              "  0.0773249939084053,\n",
              "  0.02504054643213749,\n",
              "  -0.04800678789615631,\n",
              "  -0.08252816647291183,\n",
              "  0.052310116589069366,\n",
              "  0.03972790762782097,\n",
              "  -0.026744436472654343,\n",
              "  -0.04055478423833847,\n",
              "  -0.02971818298101425,\n",
              "  -0.0018342203693464398,\n",
              "  -0.02614326775074005,\n",
              "  -0.008528783917427063,\n",
              "  0.030170736834406853,\n",
              "  -0.010246800258755684,\n",
              "  0.12468991428613663,\n",
              "  0.1276259571313858,\n",
              "  -0.0668894425034523,\n",
              "  -0.04066978022456169,\n",
              "  0.06705993413925171,\n",
              "  -0.022301508113741875,\n",
              "  0.05810258537530899,\n",
              "  0.05825943127274513,\n",
              "  0.026779508218169212,\n",
              "  -0.07465385645627975,\n",
              "  -0.02294934168457985,\n",
              "  -0.0014864584663882852,\n",
              "  -0.007473824080079794,\n",
              "  -0.01350305788218975,\n",
              "  -0.10531143099069595,\n",
              "  -0.017774246633052826,\n",
              "  -0.03025158680975437,\n",
              "  -0.030696434900164604,\n",
              "  0.02733081392943859,\n",
              "  0.011551248840987682,\n",
              "  0.1384696662425995,\n",
              "  0.030787957832217216,\n",
              "  -0.07916421443223953,\n",
              "  0.057474665343761444,\n",
              "  0.0993548035621643,\n",
              "  0.019687486812472343,\n",
              "  -0.000783231167588383,\n",
              "  0.003148796269670129,\n",
              "  -0.043086618185043335,\n",
              "  -0.03682556748390198,\n",
              "  -0.01857369765639305,\n",
              "  0.11145009100437164,\n",
              "  -0.023821091279387474,\n",
              "  0.032155055552721024,\n",
              "  0.0046234834007918835,\n",
              "  -0.05540180206298828,\n",
              "  -0.01962991990149021,\n",
              "  0.057898882776498795,\n",
              "  0.04590165987610817,\n",
              "  -0.07079996168613434,\n",
              "  -0.01446571946144104,\n",
              "  0.0632266104221344,\n",
              "  -0.0176745243370533,\n",
              "  -0.025989867746829987,\n",
              "  -0.0038166986778378487,\n",
              "  0.0265960693359375,\n",
              "  0.010702444240450859,\n",
              "  1.4625602879920377e-34,\n",
              "  0.0815412625670433,\n",
              "  0.018681742250919342,\n",
              "  0.00420060008764267,\n",
              "  0.011843817308545113,\n",
              "  0.06687920540571213,\n",
              "  0.011784262023866177,\n",
              "  -0.029814863577485085,\n",
              "  -0.04030779004096985,\n",
              "  0.10200134664773941,\n",
              "  0.04607018455862999,\n",
              "  -0.04139571264386177,\n",
              "  0.02790202386677265,\n",
              "  -0.024749750271439552,\n",
              "  -0.052839942276477814,\n",
              "  -0.05641408637166023,\n",
              "  0.03874824568629265,\n",
              "  -0.004815001040697098,\n",
              "  0.010181233286857605,\n",
              "  -0.12005569040775299,\n",
              "  0.022325340658426285,\n",
              "  -0.041271306574344635,\n",
              "  0.08442763239145279,\n",
              "  -0.07295310497283936,\n",
              "  0.023137209936976433,\n",
              "  0.03302652761340141,\n",
              "  0.008747139014303684,\n",
              "  0.001823863829486072,\n",
              "  -0.03029407560825348,\n",
              "  0.09362738579511642,\n",
              "  0.01737353950738907,\n",
              "  -0.06341512501239777,\n",
              "  -0.012833740562200546,\n",
              "  -0.026582369580864906,\n",
              "  -0.0833800658583641,\n",
              "  -0.009879832156002522,\n",
              "  -0.0315113328397274,\n",
              "  0.08412449061870575,\n",
              "  -0.05461176112294197,\n",
              "  -0.015288250520825386,\n",
              "  0.0626043975353241,\n",
              "  0.07081731408834457,\n",
              "  0.05190552398562431,\n",
              "  -0.03949790447950363,\n",
              "  0.0036285347305238247,\n",
              "  0.0030771673191338778,\n",
              "  -0.021355988457798958,\n",
              "  0.026032157242298126,\n",
              "  0.02984631061553955,\n",
              "  -0.07123123109340668,\n",
              "  -0.03759271278977394,\n",
              "  -0.0421319380402565,\n",
              "  0.024498287588357925,\n",
              "  -0.00358476210385561,\n",
              "  0.05918678641319275,\n",
              "  0.03287835791707039,\n",
              "  0.006032948847860098,\n",
              "  0.013059896416962147,\n",
              "  -0.04747907817363739,\n",
              "  -0.0220289658755064,\n",
              "  0.0016504115192219615,\n",
              "  -0.026562687009572983,\n",
              "  0.01722971722483635,\n",
              "  0.03495978191494942,\n",
              "  0.09571752697229385,\n",
              "  -0.017382841557264328,\n",
              "  -0.052063457667827606,\n",
              "  0.06783439218997955,\n",
              "  -0.04972369223833084,\n",
              "  -0.06430160999298096,\n",
              "  -0.06028144061565399,\n",
              "  0.05366380885243416,\n",
              "  -0.026363437995314598,\n",
              "  0.011585023254156113,\n",
              "  0.0036846559960395098,\n",
              "  -0.04970444738864899,\n",
              "  -0.10748790204524994,\n",
              "  -0.05358228087425232,\n",
              "  -0.1075178012251854,\n",
              "  0.009695538319647312,\n",
              "  0.10285574197769165,\n",
              "  0.0322301909327507,\n",
              "  -0.04502059891819954,\n",
              "  0.02167011983692646,\n",
              "  0.06571963429450989,\n",
              "  -0.005667978432029486,\n",
              "  0.0547139048576355,\n",
              "  -0.0250965878367424,\n",
              "  -0.022065799683332443,\n",
              "  -0.022929580882191658,\n",
              "  -0.05333424359560013,\n",
              "  -0.11197595298290253,\n",
              "  -0.04954782500863075,\n",
              "  -0.1081303134560585,\n",
              "  0.009991403669118881,\n",
              "  0.013682197779417038,\n",
              "  -2.4181201041528766e-08,\n",
              "  0.012032964266836643,\n",
              "  -0.0043035545386374,\n",
              "  -0.036434173583984375,\n",
              "  -0.026912789791822433,\n",
              "  0.045798931270837784,\n",
              "  -0.02262081392109394,\n",
              "  0.01147775910794735,\n",
              "  0.032354190945625305,\n",
              "  0.00895508099347353,\n",
              "  -0.003456991398707032,\n",
              "  0.08237927407026291,\n",
              "  -0.043174583464860916,\n",
              "  -0.06688737869262695,\n",
              "  0.013865815475583076,\n",
              "  0.10077892988920212,\n",
              "  0.023584790527820587,\n",
              "  0.05718878656625748,\n",
              "  0.07104067504405975,\n",
              "  -0.025641383603215218,\n",
              "  0.01953716017305851,\n",
              "  0.05564267933368683,\n",
              "  0.029740851372480392,\n",
              "  -0.05657592788338661,\n",
              "  0.039191313087940216,\n",
              "  0.041622593998909,\n",
              "  -0.0035657736007124186,\n",
              "  -0.053435757756233215,\n",
              "  0.09296093136072159,\n",
              "  -0.029678406193852425,\n",
              "  0.014633618295192719,\n",
              "  0.017423029989004135,\n",
              "  -0.030595730990171432,\n",
              "  -0.009884190745651722,\n",
              "  0.01966814696788788,\n",
              "  0.013358335942029953,\n",
              "  -0.011985785327851772,\n",
              "  0.09991294890642166,\n",
              "  -0.04233766347169876,\n",
              "  0.060376137495040894,\n",
              "  0.03509579226374626,\n",
              "  -0.07759317755699158,\n",
              "  0.052661649882793427,\n",
              "  0.01345671433955431,\n",
              "  0.0916864275932312,\n",
              "  0.0495479442179203,\n",
              "  -0.0075718117877841,\n",
              "  -0.04746782034635544,\n",
              "  0.09632749110460281,\n",
              "  -0.026856422424316406,\n",
              "  -0.04663064703345299,\n",
              "  -0.04375374689698219,\n",
              "  0.004621086176484823,\n",
              "  -0.0031482817139476538,\n",
              "  0.10456416010856628,\n",
              "  0.007477732840925455,\n",
              "  0.03373180702328682,\n",
              "  0.02876846119761467,\n",
              "  -0.013985708355903625,\n",
              "  -0.07204986363649368,\n",
              "  0.059204574674367905,\n",
              "  0.03382377699017525,\n",
              "  0.035755280405282974,\n",
              "  -0.046447914093732834,\n",
              "  -0.04287821426987648]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ready_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5VdF4tr0NAP",
        "outputId": "7a105075-4bf2-4f07-9efd-d215bd43347c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to MongoDB successfully!\n",
            "Available databases: ['Candidate', 'LLM_Embeddings_Jobs', 'test_database', 'admin', 'local']\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3yOuXEVA2iuU"
      },
      "outputs": [],
      "source": [
        "import pymongo\n",
        "MONGO_URI = \"mongodb+srv://LLM_User:User_llm01@clusterllm.saneb.mongodb.net/?retryWrites=true&w=majority&appName=ClusterLLM\"\n",
        "def get_mongo_client(mongo_uri):\n",
        "  # establish the connection\n",
        "  client = pymongo.MongoClient(mongo_uri)\n",
        "if not MONGO_URI:\n",
        "  print(\"MONGO_URI not set in environment variables\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZDacJBMn2mtq"
      },
      "outputs": [],
      "source": [
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "db = client['LLM_Embeddings_Jobs']\n",
        "collection = db['test_collection01']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsVlLlw61E-M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xerPDZVV3cpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSQWKbdN1E3t",
        "outputId": "44ca8d86-c62a-4f83-c8b1-ec488a88fca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bhagyeshshinde/Documents/new_test_project/env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/Users/bhagyeshshinde/Documents/new_test_project/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pymongo\n",
        "import uuid\n",
        "from typing import List, Union\n",
        "import hashlib\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# remove this in prod ----------------------------------------------------------------\n",
        "MONGO_URI = \"mongodb+srv://LLM_User:User_llm01@clusterllm.saneb.mongodb.net/?retryWrites=true&w=majority&appName=ClusterLLM\"\n",
        "# remove this in prod----------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "def load_doc(doc_name):\n",
        "    loader = PyPDFLoader(doc_name)\n",
        "    pages = loader.load()\n",
        "    return pages\n",
        "\n",
        "  \n",
        "def mongo_setup(mongo_uri):\n",
        "    client = pymongo.MongoClient(mongo_uri)\n",
        "    db = client['LLM_Embeddings_Jobs']\n",
        "    collection = db['test_collection01']\n",
        "    return collection\n",
        "\n",
        "\n",
        "def deterministic_uuid(content: Union[str, bytes]) -> str:\n",
        "    \"\"\"Creates deterministic UUID on hash value of string or byte content.\n",
        "\n",
        "    Args:\n",
        "        content: String or byte representation of data.\n",
        "\n",
        "    Returns:\n",
        "        UUID of the content.\n",
        "    \"\"\"\n",
        "    if isinstance(content, str):\n",
        "        content_bytes = content.encode(\"utf-8\")\n",
        "    elif isinstance(content, bytes):\n",
        "        content_bytes = content\n",
        "    else:\n",
        "        raise ValueError(f\"Content type {type(content)} not supported!\")\n",
        "\n",
        "    hash_object = hashlib.sha256(content_bytes)\n",
        "    hash_hex = hash_object.hexdigest()\n",
        "    namespace = uuid.UUID(\"00000000-0000-0000-0000-000000000000\")\n",
        "    content_uuid = str(uuid.uuid5(namespace, hash_hex))\n",
        "\n",
        "    return content_uuid\n",
        "\n",
        "def doc_embedor(chunks: List, jd_name: str):\n",
        "    embedded_docs = []\n",
        "    for doc in chunks:\n",
        "        # Assuming `model.encode` generates embeddings for the document\n",
        "        embedding = model.encode(doc.page_content)  \n",
        "        embedding = embedding.tolist()\n",
        "\n",
        "        # Create a deterministic UUID for the document content\n",
        "        id = deterministic_uuid(doc.page_content)+\"-\"+ jd_name\n",
        "\n",
        "        # Append the document data and embedding to the embedded_docs list\n",
        "        embedded_docs.append({\"jd_id\": id,\"data\": doc.page_content, \"embedding\": embedding})\n",
        "\n",
        "    return embedded_docs\n",
        "\n",
        "\n",
        "def get_chunked_data(data,chunk_size,chunk_overlap):\n",
        "    \n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = chunk_size,\n",
        "    chunk_overlap  = chunk_overlap,\n",
        "    length_function = len,\n",
        "  )\n",
        "  return text_splitter.split_documents(data)\n",
        "\n",
        "\n",
        "def run(doc_name,jd_name):\n",
        "    pages=load_doc(doc_name)\n",
        "    chunks = get_chunked_data(pages, 200, 50)\n",
        "    ready_data=doc_embedor(chunks,jd_name)\n",
        "    collection=mongo_setup(MONGO_URI)\n",
        "    collection.insert_many(ready_data)\n",
        "    return \"data processing completed\"\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data processing completed'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run(\"Data Scientist Job Description.pdf\", \"data_science\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
